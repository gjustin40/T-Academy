{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝을 위한 PyTorch 활용법\n",
    "## Chapter 2. Neural Network\n",
    "- y = x**2 + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = 10000\n",
    "epoch_num = 10000\n",
    "\n",
    "noise = init.normal_(torch.Tensor(data_num, 1), std=1)\n",
    "x = init.uniform_(torch.Tensor(data_num, 1), -10, 10)\n",
    "\n",
    "y = x**2 + 3\n",
    "y_noise = y + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'y')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAFACAYAAADqPiRCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b4b9bd30f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(x.numpy(), y_noise.numpy(), color='g')\n",
    "plt.scatter(x.numpy(), y.numpy(), color='r')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(1,6),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6,10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,1))\n",
    "\n",
    "output = model(Variable(x))\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2239.4504, grad_fn=<MseLossBackward>)\n",
      "tensor(2115.0664, grad_fn=<MseLossBackward>)\n",
      "tensor(1275.5067, grad_fn=<MseLossBackward>)\n",
      "tensor(134.0091, grad_fn=<MseLossBackward>)\n",
      "tensor(128.4024, grad_fn=<MseLossBackward>)\n",
      "tensor(123.8546, grad_fn=<MseLossBackward>)\n",
      "tensor(119.7173, grad_fn=<MseLossBackward>)\n",
      "tensor(115.8842, grad_fn=<MseLossBackward>)\n",
      "tensor(112.2979, grad_fn=<MseLossBackward>)\n",
      "tensor(108.8503, grad_fn=<MseLossBackward>)\n",
      "tensor(105.6173, grad_fn=<MseLossBackward>)\n",
      "tensor(102.5523, grad_fn=<MseLossBackward>)\n",
      "tensor(99.6188, grad_fn=<MseLossBackward>)\n",
      "tensor(96.7926, grad_fn=<MseLossBackward>)\n",
      "tensor(94.0750, grad_fn=<MseLossBackward>)\n",
      "tensor(91.4470, grad_fn=<MseLossBackward>)\n",
      "tensor(88.8982, grad_fn=<MseLossBackward>)\n",
      "tensor(86.4202, grad_fn=<MseLossBackward>)\n",
      "tensor(84.0062, grad_fn=<MseLossBackward>)\n",
      "tensor(81.6510, grad_fn=<MseLossBackward>)\n",
      "tensor(79.3485, grad_fn=<MseLossBackward>)\n",
      "tensor(77.0931, grad_fn=<MseLossBackward>)\n",
      "tensor(74.8793, grad_fn=<MseLossBackward>)\n",
      "tensor(72.7022, grad_fn=<MseLossBackward>)\n",
      "tensor(70.5554, grad_fn=<MseLossBackward>)\n",
      "tensor(68.4378, grad_fn=<MseLossBackward>)\n",
      "tensor(66.3504, grad_fn=<MseLossBackward>)\n",
      "tensor(64.2959, grad_fn=<MseLossBackward>)\n",
      "tensor(62.2726, grad_fn=<MseLossBackward>)\n",
      "tensor(60.2806, grad_fn=<MseLossBackward>)\n",
      "tensor(58.3152, grad_fn=<MseLossBackward>)\n",
      "tensor(56.3848, grad_fn=<MseLossBackward>)\n",
      "tensor(54.4881, grad_fn=<MseLossBackward>)\n",
      "tensor(52.6259, grad_fn=<MseLossBackward>)\n",
      "tensor(50.8019, grad_fn=<MseLossBackward>)\n",
      "tensor(49.0168, grad_fn=<MseLossBackward>)\n",
      "tensor(47.2694, grad_fn=<MseLossBackward>)\n",
      "tensor(45.5642, grad_fn=<MseLossBackward>)\n",
      "tensor(43.9039, grad_fn=<MseLossBackward>)\n",
      "tensor(42.2906, grad_fn=<MseLossBackward>)\n",
      "tensor(40.7279, grad_fn=<MseLossBackward>)\n",
      "tensor(39.2141, grad_fn=<MseLossBackward>)\n",
      "tensor(37.7522, grad_fn=<MseLossBackward>)\n",
      "tensor(36.3431, grad_fn=<MseLossBackward>)\n",
      "tensor(34.9863, grad_fn=<MseLossBackward>)\n",
      "tensor(33.6831, grad_fn=<MseLossBackward>)\n",
      "tensor(32.4344, grad_fn=<MseLossBackward>)\n",
      "tensor(31.2405, grad_fn=<MseLossBackward>)\n",
      "tensor(30.1045, grad_fn=<MseLossBackward>)\n",
      "tensor(29.0252, grad_fn=<MseLossBackward>)\n",
      "tensor(27.9995, grad_fn=<MseLossBackward>)\n",
      "tensor(27.0294, grad_fn=<MseLossBackward>)\n",
      "tensor(26.1185, grad_fn=<MseLossBackward>)\n",
      "tensor(25.2670, grad_fn=<MseLossBackward>)\n",
      "tensor(24.4706, grad_fn=<MseLossBackward>)\n",
      "tensor(23.7281, grad_fn=<MseLossBackward>)\n",
      "tensor(23.0359, grad_fn=<MseLossBackward>)\n",
      "tensor(22.3890, grad_fn=<MseLossBackward>)\n",
      "tensor(21.7862, grad_fn=<MseLossBackward>)\n",
      "tensor(21.2233, grad_fn=<MseLossBackward>)\n",
      "tensor(20.6977, grad_fn=<MseLossBackward>)\n",
      "tensor(20.2057, grad_fn=<MseLossBackward>)\n",
      "tensor(19.7487, grad_fn=<MseLossBackward>)\n",
      "tensor(19.3241, grad_fn=<MseLossBackward>)\n",
      "tensor(18.9284, grad_fn=<MseLossBackward>)\n",
      "tensor(18.5591, grad_fn=<MseLossBackward>)\n",
      "tensor(18.2137, grad_fn=<MseLossBackward>)\n",
      "tensor(17.8884, grad_fn=<MseLossBackward>)\n",
      "tensor(17.5824, grad_fn=<MseLossBackward>)\n",
      "tensor(17.2955, grad_fn=<MseLossBackward>)\n",
      "tensor(17.0252, grad_fn=<MseLossBackward>)\n",
      "tensor(16.7706, grad_fn=<MseLossBackward>)\n",
      "tensor(16.5311, grad_fn=<MseLossBackward>)\n",
      "tensor(16.3042, grad_fn=<MseLossBackward>)\n",
      "tensor(16.0882, grad_fn=<MseLossBackward>)\n",
      "tensor(15.8809, grad_fn=<MseLossBackward>)\n",
      "tensor(15.6816, grad_fn=<MseLossBackward>)\n",
      "tensor(15.4895, grad_fn=<MseLossBackward>)\n",
      "tensor(15.3040, grad_fn=<MseLossBackward>)\n",
      "tensor(15.1239, grad_fn=<MseLossBackward>)\n",
      "tensor(14.9469, grad_fn=<MseLossBackward>)\n",
      "tensor(14.7720, grad_fn=<MseLossBackward>)\n",
      "tensor(14.5993, grad_fn=<MseLossBackward>)\n",
      "tensor(14.4275, grad_fn=<MseLossBackward>)\n",
      "tensor(14.2564, grad_fn=<MseLossBackward>)\n",
      "tensor(14.0880, grad_fn=<MseLossBackward>)\n",
      "tensor(13.9229, grad_fn=<MseLossBackward>)\n",
      "tensor(13.7620, grad_fn=<MseLossBackward>)\n",
      "tensor(13.6039, grad_fn=<MseLossBackward>)\n",
      "tensor(13.4467, grad_fn=<MseLossBackward>)\n",
      "tensor(13.2897, grad_fn=<MseLossBackward>)\n",
      "tensor(13.1320, grad_fn=<MseLossBackward>)\n",
      "tensor(12.9737, grad_fn=<MseLossBackward>)\n",
      "tensor(12.8142, grad_fn=<MseLossBackward>)\n",
      "tensor(12.6541, grad_fn=<MseLossBackward>)\n",
      "tensor(12.4931, grad_fn=<MseLossBackward>)\n",
      "tensor(12.3305, grad_fn=<MseLossBackward>)\n",
      "tensor(12.1662, grad_fn=<MseLossBackward>)\n",
      "tensor(12.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(11.8342, grad_fn=<MseLossBackward>)\n",
      "tensor(11.6672, grad_fn=<MseLossBackward>)\n",
      "tensor(11.5001, grad_fn=<MseLossBackward>)\n",
      "tensor(11.3308, grad_fn=<MseLossBackward>)\n",
      "tensor(11.1573, grad_fn=<MseLossBackward>)\n",
      "tensor(10.9847, grad_fn=<MseLossBackward>)\n",
      "tensor(10.8123, grad_fn=<MseLossBackward>)\n",
      "tensor(10.6408, grad_fn=<MseLossBackward>)\n",
      "tensor(10.4704, grad_fn=<MseLossBackward>)\n",
      "tensor(10.3015, grad_fn=<MseLossBackward>)\n",
      "tensor(10.1342, grad_fn=<MseLossBackward>)\n",
      "tensor(9.9690, grad_fn=<MseLossBackward>)\n",
      "tensor(9.8061, grad_fn=<MseLossBackward>)\n",
      "tensor(9.6457, grad_fn=<MseLossBackward>)\n",
      "tensor(9.4879, grad_fn=<MseLossBackward>)\n",
      "tensor(9.3340, grad_fn=<MseLossBackward>)\n",
      "tensor(9.1839, grad_fn=<MseLossBackward>)\n",
      "tensor(9.0373, grad_fn=<MseLossBackward>)\n",
      "tensor(8.8953, grad_fn=<MseLossBackward>)\n",
      "tensor(8.7571, grad_fn=<MseLossBackward>)\n",
      "tensor(8.6226, grad_fn=<MseLossBackward>)\n",
      "tensor(8.4922, grad_fn=<MseLossBackward>)\n",
      "tensor(8.3658, grad_fn=<MseLossBackward>)\n",
      "tensor(8.2438, grad_fn=<MseLossBackward>)\n",
      "tensor(8.1255, grad_fn=<MseLossBackward>)\n",
      "tensor(8.0104, grad_fn=<MseLossBackward>)\n",
      "tensor(7.8979, grad_fn=<MseLossBackward>)\n",
      "tensor(7.7881, grad_fn=<MseLossBackward>)\n",
      "tensor(7.6808, grad_fn=<MseLossBackward>)\n",
      "tensor(7.5757, grad_fn=<MseLossBackward>)\n",
      "tensor(7.4735, grad_fn=<MseLossBackward>)\n",
      "tensor(7.3737, grad_fn=<MseLossBackward>)\n",
      "tensor(7.2762, grad_fn=<MseLossBackward>)\n",
      "tensor(7.1806, grad_fn=<MseLossBackward>)\n",
      "tensor(7.0869, grad_fn=<MseLossBackward>)\n",
      "tensor(6.9949, grad_fn=<MseLossBackward>)\n",
      "tensor(6.9048, grad_fn=<MseLossBackward>)\n",
      "tensor(6.8165, grad_fn=<MseLossBackward>)\n",
      "tensor(6.7298, grad_fn=<MseLossBackward>)\n",
      "tensor(6.6448, grad_fn=<MseLossBackward>)\n",
      "tensor(6.5612, grad_fn=<MseLossBackward>)\n",
      "tensor(6.4793, grad_fn=<MseLossBackward>)\n",
      "tensor(6.3991, grad_fn=<MseLossBackward>)\n",
      "tensor(6.3206, grad_fn=<MseLossBackward>)\n",
      "tensor(6.2438, grad_fn=<MseLossBackward>)\n",
      "tensor(6.1686, grad_fn=<MseLossBackward>)\n",
      "tensor(6.0948, grad_fn=<MseLossBackward>)\n",
      "tensor(6.0223, grad_fn=<MseLossBackward>)\n",
      "tensor(5.9511, grad_fn=<MseLossBackward>)\n",
      "tensor(5.8814, grad_fn=<MseLossBackward>)\n",
      "tensor(5.8130, grad_fn=<MseLossBackward>)\n",
      "tensor(5.7459, grad_fn=<MseLossBackward>)\n",
      "tensor(5.6805, grad_fn=<MseLossBackward>)\n",
      "tensor(5.6164, grad_fn=<MseLossBackward>)\n",
      "tensor(5.5537, grad_fn=<MseLossBackward>)\n",
      "tensor(5.4922, grad_fn=<MseLossBackward>)\n",
      "tensor(5.4321, grad_fn=<MseLossBackward>)\n",
      "tensor(5.3732, grad_fn=<MseLossBackward>)\n",
      "tensor(5.3154, grad_fn=<MseLossBackward>)\n",
      "tensor(5.2588, grad_fn=<MseLossBackward>)\n",
      "tensor(5.2033, grad_fn=<MseLossBackward>)\n",
      "tensor(5.1440, grad_fn=<MseLossBackward>)\n",
      "tensor(5.0797, grad_fn=<MseLossBackward>)\n",
      "tensor(5.0175, grad_fn=<MseLossBackward>)\n",
      "tensor(4.9572, grad_fn=<MseLossBackward>)\n",
      "tensor(4.8986, grad_fn=<MseLossBackward>)\n",
      "tensor(4.8416, grad_fn=<MseLossBackward>)\n",
      "tensor(4.7861, grad_fn=<MseLossBackward>)\n",
      "tensor(4.7322, grad_fn=<MseLossBackward>)\n",
      "tensor(4.6800, grad_fn=<MseLossBackward>)\n",
      "tensor(4.6293, grad_fn=<MseLossBackward>)\n",
      "tensor(4.5801, grad_fn=<MseLossBackward>)\n",
      "tensor(4.5323, grad_fn=<MseLossBackward>)\n",
      "tensor(4.4859, grad_fn=<MseLossBackward>)\n",
      "tensor(4.4408, grad_fn=<MseLossBackward>)\n",
      "tensor(4.3969, grad_fn=<MseLossBackward>)\n",
      "tensor(4.3543, grad_fn=<MseLossBackward>)\n",
      "tensor(4.3129, grad_fn=<MseLossBackward>)\n",
      "tensor(4.2725, grad_fn=<MseLossBackward>)\n",
      "tensor(4.2331, grad_fn=<MseLossBackward>)\n",
      "tensor(4.1947, grad_fn=<MseLossBackward>)\n",
      "tensor(4.1574, grad_fn=<MseLossBackward>)\n",
      "tensor(4.1211, grad_fn=<MseLossBackward>)\n",
      "tensor(4.0857, grad_fn=<MseLossBackward>)\n",
      "tensor(4.0512, grad_fn=<MseLossBackward>)\n",
      "tensor(4.0175, grad_fn=<MseLossBackward>)\n",
      "tensor(3.9846, grad_fn=<MseLossBackward>)\n",
      "tensor(3.9524, grad_fn=<MseLossBackward>)\n",
      "tensor(3.9210, grad_fn=<MseLossBackward>)\n",
      "tensor(3.8902, grad_fn=<MseLossBackward>)\n",
      "tensor(3.8601, grad_fn=<MseLossBackward>)\n",
      "tensor(3.8306, grad_fn=<MseLossBackward>)\n",
      "tensor(3.8017, grad_fn=<MseLossBackward>)\n",
      "tensor(3.7734, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7457, grad_fn=<MseLossBackward>)\n",
      "tensor(3.7186, grad_fn=<MseLossBackward>)\n",
      "tensor(3.6920, grad_fn=<MseLossBackward>)\n",
      "tensor(3.6659, grad_fn=<MseLossBackward>)\n",
      "tensor(3.6404, grad_fn=<MseLossBackward>)\n",
      "tensor(3.6153, grad_fn=<MseLossBackward>)\n",
      "tensor(3.5908, grad_fn=<MseLossBackward>)\n",
      "tensor(3.5668, grad_fn=<MseLossBackward>)\n",
      "tensor(3.5432, grad_fn=<MseLossBackward>)\n",
      "tensor(3.5199, grad_fn=<MseLossBackward>)\n",
      "tensor(3.4972, grad_fn=<MseLossBackward>)\n",
      "tensor(3.4749, grad_fn=<MseLossBackward>)\n",
      "tensor(3.4530, grad_fn=<MseLossBackward>)\n",
      "tensor(3.4315, grad_fn=<MseLossBackward>)\n",
      "tensor(3.4104, grad_fn=<MseLossBackward>)\n",
      "tensor(3.3897, grad_fn=<MseLossBackward>)\n",
      "tensor(3.3694, grad_fn=<MseLossBackward>)\n",
      "tensor(3.3495, grad_fn=<MseLossBackward>)\n",
      "tensor(3.3300, grad_fn=<MseLossBackward>)\n",
      "tensor(3.3107, grad_fn=<MseLossBackward>)\n",
      "tensor(3.2918, grad_fn=<MseLossBackward>)\n",
      "tensor(3.2733, grad_fn=<MseLossBackward>)\n",
      "tensor(3.2550, grad_fn=<MseLossBackward>)\n",
      "tensor(3.2370, grad_fn=<MseLossBackward>)\n",
      "tensor(3.2194, grad_fn=<MseLossBackward>)\n",
      "tensor(3.2021, grad_fn=<MseLossBackward>)\n",
      "tensor(3.1851, grad_fn=<MseLossBackward>)\n",
      "tensor(3.1683, grad_fn=<MseLossBackward>)\n",
      "tensor(3.1518, grad_fn=<MseLossBackward>)\n",
      "tensor(3.1357, grad_fn=<MseLossBackward>)\n",
      "tensor(3.1197, grad_fn=<MseLossBackward>)\n",
      "tensor(3.1040, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0885, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0733, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0583, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0436, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0291, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0148, grad_fn=<MseLossBackward>)\n",
      "tensor(3.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(2.9866, grad_fn=<MseLossBackward>)\n",
      "tensor(2.9728, grad_fn=<MseLossBackward>)\n",
      "tensor(2.9591, grad_fn=<MseLossBackward>)\n",
      "tensor(2.9456, grad_fn=<MseLossBackward>)\n",
      "tensor(2.9323, grad_fn=<MseLossBackward>)\n",
      "tensor(2.9191, grad_fn=<MseLossBackward>)\n",
      "tensor(2.9061, grad_fn=<MseLossBackward>)\n",
      "tensor(2.8933, grad_fn=<MseLossBackward>)\n",
      "tensor(2.8807, grad_fn=<MseLossBackward>)\n",
      "tensor(2.8683, grad_fn=<MseLossBackward>)\n",
      "tensor(2.8560, grad_fn=<MseLossBackward>)\n",
      "tensor(2.8439, grad_fn=<MseLossBackward>)\n",
      "tensor(2.8321, grad_fn=<MseLossBackward>)\n",
      "tensor(2.8203, grad_fn=<MseLossBackward>)\n",
      "tensor(2.8088, grad_fn=<MseLossBackward>)\n",
      "tensor(2.7973, grad_fn=<MseLossBackward>)\n",
      "tensor(2.7860, grad_fn=<MseLossBackward>)\n",
      "tensor(2.7747, grad_fn=<MseLossBackward>)\n",
      "tensor(2.7637, grad_fn=<MseLossBackward>)\n",
      "tensor(2.7528, grad_fn=<MseLossBackward>)\n",
      "tensor(2.7421, grad_fn=<MseLossBackward>)\n",
      "tensor(2.7316, grad_fn=<MseLossBackward>)\n",
      "tensor(2.7212, grad_fn=<MseLossBackward>)\n",
      "tensor(2.7110, grad_fn=<MseLossBackward>)\n",
      "tensor(2.7009, grad_fn=<MseLossBackward>)\n",
      "tensor(2.6909, grad_fn=<MseLossBackward>)\n",
      "tensor(2.6810, grad_fn=<MseLossBackward>)\n",
      "tensor(2.6713, grad_fn=<MseLossBackward>)\n",
      "tensor(2.6617, grad_fn=<MseLossBackward>)\n",
      "tensor(2.6522, grad_fn=<MseLossBackward>)\n",
      "tensor(2.6428, grad_fn=<MseLossBackward>)\n",
      "tensor(2.6335, grad_fn=<MseLossBackward>)\n",
      "tensor(2.6244, grad_fn=<MseLossBackward>)\n",
      "tensor(2.6154, grad_fn=<MseLossBackward>)\n",
      "tensor(2.6065, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5977, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5890, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5805, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5720, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5636, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5553, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5471, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5391, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5311, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5232, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5154, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5078, grad_fn=<MseLossBackward>)\n",
      "tensor(2.5002, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4927, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4852, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4778, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4705, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4633, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4561, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4491, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4420, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4350, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4280, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4212, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4143, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4075, grad_fn=<MseLossBackward>)\n",
      "tensor(2.4008, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3941, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3875, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3810, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3745, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3681, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3617, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3554, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3491, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3429, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3367, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3306, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3246, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3186, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3126, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3067, grad_fn=<MseLossBackward>)\n",
      "tensor(2.3009, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2950, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2893, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2835, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2778, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2722, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2666, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2610, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2554, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2499, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2444, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2390, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2335, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2281, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2227, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2173, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2120, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2066, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2014, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1962, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1911, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1861, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1811, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1763, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1715, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1669, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1622, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1576, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1531, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1486, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1441, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1396, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1352, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1308, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1264, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1220, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1177, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1134, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1091, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1049, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1007, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0965, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0924, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0883, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0842, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0802, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0762, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0722, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0682, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0643, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0604, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0565, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0526, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0488, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0450, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0412, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0375, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0337, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0300, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0263, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0226, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0189, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0152, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0115, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0079, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0043, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9970, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9935, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9899, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9863, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9828, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9792, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9757, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9722, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9687, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9653, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9618, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9583, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9549, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9514, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9480, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9446, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9413, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9379, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9346, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9312, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9279, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9246, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9214, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9181, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9149, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9117, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9085, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9053, grad_fn=<MseLossBackward>)\n",
      "tensor(1.9021, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8989, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8958, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8926, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8895, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8863, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8832, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8801, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8770, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8739, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8709, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8678, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8648, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8618, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8588, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8558, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8528, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8498, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8468, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8439, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8409, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8380, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8351, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8321, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8292, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8263, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8234, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8206, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8177, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8148, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8119, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8091, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8063, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8034, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8006, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7978, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7950, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7922, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7894, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7866, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7839, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7811, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7783, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7755, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7727, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7700, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7672, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7645, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7618, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7590, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7563, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7536, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7509, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7482, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7455, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7428, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7401, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7375, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7348, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7322, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7295, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7269, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7243, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7217, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7191, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7164, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7138, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7112, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7086, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7061, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7035, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7009, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6984, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6958, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6933, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6907, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6882, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6856, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6831, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6806, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6780, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6755, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6730, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6705, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6680, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6655, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6630, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6605, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6580, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6556, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6531, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6506, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6482, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6457, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6433, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6408, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss_arr = []\n",
    "\n",
    "label = Variable(y_noise)\n",
    "for i in range(epoch_num):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(Variable(x))\n",
    "    loss = loss_func(output, label)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "        print(loss)\n",
    "    loss_arr.append(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-1.0005],\n",
      "        [-0.3561],\n",
      "        [-0.8439],\n",
      "        [ 0.1815],\n",
      "        [-0.6349],\n",
      "        [ 0.8644]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.2571, -1.6913, -1.6403, -1.2731,  0.2206, -1.2251], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.2033,  0.6113,  0.8453,  0.3072,  0.3298,  0.5530],\n",
      "        [-0.2042, -0.0042, -0.2886,  0.3183, -0.0496, -0.3248],\n",
      "        [-0.1190,  0.1400,  0.1537, -0.1274, -0.2426,  0.3481],\n",
      "        [-0.0795, -0.2504, -0.1138,  0.3946,  0.3568,  0.0981],\n",
      "        [-0.0139,  0.1790, -0.1093,  0.5845, -0.0262,  0.5661],\n",
      "        [-0.2398,  0.9369,  0.9925,  0.6915, -0.3227,  0.5111],\n",
      "        [-0.1161,  0.7014,  0.7025,  0.8097,  0.1541,  0.8167],\n",
      "        [ 0.3563, -0.3342,  0.0958,  0.3790, -0.2077, -0.0447],\n",
      "        [ 0.2625, -0.3744, -0.1863,  0.5823, -0.1977,  0.4928],\n",
      "        [ 0.4054,  0.0353,  0.1034, -0.1279,  0.4283,  0.6107]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.7930,  0.1752, -0.3085, -0.3137,  0.6664, -1.8184, -0.7425, -0.2477,\n",
      "         0.4273,  0.3073], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.2326, -0.1853,  0.1101,  0.1910,  0.0973, -0.2241, -0.0751,  0.2442,\n",
      "          0.2658,  0.0649],\n",
      "        [ 0.0793, -0.1359, -0.1575, -0.1546,  0.2845,  0.1226,  0.1262, -0.1474,\n",
      "          0.2901, -0.1498],\n",
      "        [-0.0298, -0.0158,  0.2565, -0.1565,  0.1523, -0.1900, -0.2388,  0.1173,\n",
      "          0.2290,  0.1665],\n",
      "        [-0.0491, -0.0488, -0.0873, -0.2122,  0.2827, -0.0853,  0.0643, -0.0009,\n",
      "          0.2727,  0.2589],\n",
      "        [ 0.2428, -0.2968,  0.2222,  0.1375, -0.2174,  0.0434,  0.1944, -0.1633,\n",
      "          0.2329, -0.0436],\n",
      "        [ 0.0500,  0.1285, -0.0487,  0.1326, -0.0912,  0.2078, -0.2400,  0.1775,\n",
      "          0.0747, -0.2260],\n",
      "        [ 0.2934,  0.0127,  0.3715,  0.4010,  0.4595,  1.1084,  0.4532, -0.0190,\n",
      "          0.5618,  0.3695],\n",
      "        [-0.1014, -0.0617, -0.0110, -0.0074, -0.2589, -0.2075,  0.0039, -0.1319,\n",
      "          0.0966, -0.2750],\n",
      "        [-0.3043, -0.1192, -0.1021,  0.1192, -0.0182, -0.0211,  0.0994,  0.2127,\n",
      "         -0.2147,  0.0123],\n",
      "        [ 0.0418, -0.1623,  0.2724, -0.0670, -0.2359,  0.2814,  0.4753,  0.1172,\n",
      "         -0.2529, -0.0689],\n",
      "        [ 0.1345, -0.3066,  0.1288,  0.2247, -0.3188,  0.2566, -0.0398,  0.1377,\n",
      "         -0.1316, -0.2010],\n",
      "        [ 0.0975,  0.2118, -0.1111, -0.3239,  0.2716, -0.1099, -0.1627, -0.1193,\n",
      "          0.2817, -0.0840],\n",
      "        [-0.1674, -0.0483,  0.0824,  0.3039,  0.3497, -0.1701, -0.2749, -0.1245,\n",
      "         -0.2329,  0.0670],\n",
      "        [ 0.6821,  0.3092, -0.1919, -0.0066,  0.1897,  1.0923,  0.7450,  0.1825,\n",
      "          0.1818,  0.2549],\n",
      "        [ 1.1134, -0.2281,  0.1257,  0.1900,  0.6597,  1.5531,  1.1678, -0.1460,\n",
      "          0.6756,  0.0239],\n",
      "        [-0.1977, -0.2800,  0.1272,  0.0029, -0.2408,  0.1439, -0.0121,  0.1712,\n",
      "          0.2538,  0.1148],\n",
      "        [-0.1404,  0.1889,  0.0762,  0.0274,  0.3513,  0.5460,  0.4521, -0.0247,\n",
      "          0.1081,  0.2016],\n",
      "        [-0.2420, -0.0094,  0.1196, -0.2082,  0.2019,  0.2457, -0.1937, -0.1708,\n",
      "          0.0828,  0.0202],\n",
      "        [ 0.4734, -0.1825, -0.1146, -0.0915, -0.2559,  0.7975,  0.3451, -0.2612,\n",
      "         -0.0192, -0.0375],\n",
      "        [-0.1374, -0.1385, -0.0756,  0.0995,  0.0879, -0.2155, -0.1922,  0.0736,\n",
      "          0.2745, -0.0857]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2627, -0.1036,  0.0420,  0.2327, -0.0918,  0.1492,  0.2182, -0.2723,\n",
      "         0.1902, -0.2909,  0.0214, -0.1246,  0.4310, -0.6175, -0.0635, -0.2769,\n",
      "         0.3375, -0.2792, -0.7310, -0.2469], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.1636,  0.2723, -0.0030,  0.1172,  0.2838, -0.1198,  1.5217,  0.0302,\n",
      "         -0.0597,  0.5128,  0.1230, -0.0635,  0.4076,  1.5685,  2.3785, -0.1334,\n",
      "          0.7116, -0.0907,  1.1033, -0.1935]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3305], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 질문"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
