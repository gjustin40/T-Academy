{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝을 위한 PyTorch 활용법\n",
    "## Chapter 2. Linear Regression\n",
    "- Linear Data\n",
    "- Linear Model\n",
    "- y = 2x + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn # Linear 함수\n",
    "import torch.optim as optim # gradient\n",
    "import torch.nn.init as init # 초기값\n",
    "from torch.autograd import Variable # 모델 학습용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visdom은 페이스북에서 제공하는 시각화 툴이다.\n",
    "\n",
    "from visdom import Visdom\n",
    "viz = Visdom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data\n",
    "- normal -> normal_\n",
    "- uniform -> uniform_\n",
    "- 강의와 버젼이 다름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 1000\n",
    "num_epoch = 1000\n",
    "\n",
    "noise = init.normal_(torch.FloatTensor(num_data, 1), std = 1)\n",
    "x = init.uniform_(torch.FloatTensor(num_data, 1), -10,10)\n",
    "\n",
    "y = 3*x + 5\n",
    "y_noise = y + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x21476207470>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAEyCAYAAABzmvKXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFJYiIklQWIqIJEFhKSKShP8Hl5ryyP7nP/cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x214722192e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize = (5, 5))\n",
    "plt.plot(x.numpy(), y.numpy(), color = 'r')\n",
    "plt.scatter(x.numpy(), y.numpy(), color = 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1,1) # input, output size\n",
    "output = model(Variable(x)) # \n",
    "\n",
    "loss_func = nn.MSELoss() # 이 매트릭(matric)으로 loss를 측정하겠다.\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01) # 해당 optimizer로 업데이트 하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.zero_grad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.5280]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.8455], requires_grad=True)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7212.0537, grad_fn=<MseLossBackward>)\n",
      "tensor(2.1493, grad_fn=<MseLossBackward>)\n",
      "tensor(1.7506, grad_fn=<MseLossBackward>)\n",
      "tensor(1.4844, grad_fn=<MseLossBackward>)\n",
      "tensor(1.3065, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1878, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1085, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0555, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0201, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9965, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9807, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9702, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9631, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9584, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9553, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9532, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9518, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9509, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9502, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9498, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9496, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9494, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9492, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9492, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9491, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9491, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.9490, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "loss_arr = [] # 일단 보류\n",
    "\n",
    "label = Variable(y_noise)\n",
    "# output도 variable로 감싸줘야 함(input과 같이)\n",
    "# 결과가 Variable로 감싸져서 나옴\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad() # 계산된 gradient를 초기화\n",
    "    output = model(Variable(x))\n",
    "    \n",
    "    loss = loss_func(output, label) # 정답(label)과 계산된 결과(output) 오차값\n",
    "    loss.backward() # 오차역전파\n",
    "    optimizer.step() #  해당 optimizer로 가중치값 갱신\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(loss)\n",
    "        \n",
    "    loss_arr.append(loss.data.numpy())\n",
    "    \n",
    "loss_arr = []\n",
    "\n",
    "label = Variable(y_noise)\n",
    "\n",
    "for i in range(epoch_num):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(Variable(x))\n",
    "    loss = loss_func(output, label)\n",
    "    loss.backward\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(loss)\n",
    "    loss_arr.append(loss)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Trained Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14.9980]]) tensor([1.0138])\n"
     ]
    }
   ],
   "source": [
    "param_list = list(model.parameters())\n",
    "print(param_list[0].data, param_list[1].data) # y = 2x + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Loss Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(loss_arr)), loss_arr) # loss값 시각화\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 혼자서 실습해보기\n",
    "- Linear Regression 실습하기\n",
    "- y = 15x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = 1000\n",
    "epoch_num = 1000\n",
    "noise = init.normal_(torch.Tensor(data_num, 1), std = 1)\n",
    "x = init.uniform_(torch.Tensor(data_num, 1), -10, 10)\n",
    "\n",
    "y = 15 * x + 1\n",
    "y_noise = y + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1,1)\n",
    "output = model(Variable(x))\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n",
      "tensor(7046.6709, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss_arr = []\n",
    "\n",
    "label = Variable(y_noise)\n",
    "\n",
    "for i in range(epoch_num):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(Variable(x))\n",
    "    loss = loss_func(output, label)\n",
    "    loss.backward\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(loss)\n",
    "    loss_arr.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.1012]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.9542], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
