---------------1강--------------

슈퍼바이즈드 러닝
- 이미 알고 있는 패턴을 학습하는 것

언슈퍼바이즈드 러닝
- 데이터만 있고 해당 데이터를 분류하는 것

강화학습
- 스스로 데이터를 생성하면서 학습하는 모델

딥러닝
- 인공신경망을 사용하며 하나 이상의 은닉층을 가지는 것을 말한다.

딥러닝이 뜬 이유
1. 정데되었든 안 되었던 데이터 자체가 엄청나게 많아졌기 때문에

2. 연산속도가 굉장히 빨라졌기 때문이다.(GPU)

활용 분야
1. object detection을 통해 아웃라인을 치고 세그멘테이션까지 진행

2. 이미지를 보고 문장을 생성하는 것

* Pytorch
- Facebook AI Research 안에 있는 몇몇의 사람들이 오픈소스로 만든거다.

* 파이토치 특징
- Python first
- GPU acceleration
- Linux/osx/window

* numpy와 pytorch의 연산 차이
- 자동으로 gradient를 계산할 수 없다.
- numpy는 미분을 하고 수식으로 작성을 해줘야한다.
- pytorch는 자동으로 실시해준다.

* Tensorflow와 Pytorch차이
tensor : define and run
pytorch : define by run

* Package
1. Tensor
2. nn - nueral network
3. optim
4. autograd
5. distribution
6. cuda
7. uili
8. utils.model_zoo
9. onnx - 핸드폰 디바이스
10. dataset - ImageFolder(data loader)
11. 



-----------------2강-------------------
* 선형회귀(linear regression)
- 데이터가 주어졌을 때 데이터를 가장 잘 설명하는 직선을 찾는 것
- y = w*x + b 에서 w, b를 찾는 것

- 잘 예측했는지 아닌지 측정할 척도(metric)가 필요함
- 로스함수가 metric
- ex) Mean Squared Error

- loss를 최소화하는 wb를 구하고 싶다
- loss 값을 통해서 구할 수 없을까?
* Gradient


* 선형회귀 과정 (pytorch)

data -> torch.tensor로 변환 -> model architecture
-> output -> loss -> gradients -> update(한 칸씩 옮겨줌(optimizer.step())























